# Plan-TDD Skill: Help Text Test Anti-Pattern

**Date**: 2026-01-27
**Status**: Problem identified, skill guidance needed

## Problem Statement

Test suite contains brittle help text tests (`test_cli_help.py`) that check exact wording in command help output. These tests:
1. Break on any phrasing improvement
2. Test presentation, not behavior
3. Add maintenance burden without meaningful safety
4. Don't fit TDD methodology (no hidden correctness to verify)

## Root Cause Analysis

**Primary cause**: Confusion about what should be tested in TDD

Help text tests were added December 2025 (commits 4463e87, 5085fc4) for commands like `collect`, `analyze`, `rules`, `tokens`. Tests verify exact phrases appear in help output:
- "recursively" in collect help
- "instructions", "corrections", "process" in analyze help
- "Deduplicates" in rules help
- "Requires", "Examples:" in tokens help

**Why this is an anti-pattern**:
1. **Presentation, not behavior** - TDD tests logic/behavior, not exact wording
2. **Self-evident quality** - Users immediately see if help is unclear
3. **High brittleness** - Improving phrasing breaks tests
4. **No hidden correctness** - Unlike internal functions, help is user-facing

## When Help Text Tests ARE Appropriate

**Valid cases** (rare):
- Critical facts that MUST appear (regulatory/legal requirements)
- Help text generated by complex logic (not static strings)
- Compliance verification (e.g., "must warn about data deletion")

**Invalid cases** (current situation):
- Static command descriptions
- Phrasing quality checks
- Presence of explanatory words

## Impact on TDD Runbooks

The `/plan-tdd` skill needs to recognize this pattern and avoid generating RED-GREEN cycles for:
- CLI help text (static descriptions)
- Error message phrasing (test behavior, not exact wording)
- Log output formatting (test data presence, not formatting)
- Documentation generation (unless complex logic)

## Observed Test Failures

When running `just dev` after composition API work:
```
4/285 tests failed - all in test_cli_help.py
- test_collect_help_describes_purpose
- test_analyze_help_lists_categories
- test_rules_help_describes_filtering
- test_tokens_help_is_complete_and_accurate
```

These failures indicate unrelated commands' help text changed (or tests were already brittle). The composition API TDD runbook correctly did NOT include help text cycles.

## Design Discussion Topics

1. **Skill guidance** - How should `/plan-tdd` identify presentation-only tests?
2. **Test classification** - What criteria distinguish "testable behavior" from "presentation"?
3. **Existing test audit** - Should we systematically review test suite for other anti-patterns?
4. **Skill examples** - Add help text as explicit anti-pattern in plan-tdd skill?

## Recommended Actions

**Immediate**:
- [ ] Delete `tests/test_cli_help.py` entirely (no meaningful coverage)
- [ ] Audit test suite for similar presentation tests
- [ ] Document "presentation vs behavior" in test-strategy.md

**Skill improvement**:
- [ ] Add "What NOT to test" section to plan-tdd skill
- [ ] Include help text, log formatting, error messages as examples
- [ ] Provide heuristic: "If user sees output directly, don't test exact phrasing"

**Long-term**:
- [ ] Test suite audit for brittleness patterns
- [ ] Document TDD boundaries in test-strategy.md

## Related Context

- Test file: tests/test_cli_help.py (added Dec 2025)
- Test strategy: agents/test-strategy.md
- Plan-TDD skill: .claude/skills/plan-tdd/SKILL.md
- Current failure: 4/285 tests failing on help text assertions

## References

**When tests were added**:
- 4463e87 (2025-12-20): "Enhance CLI inline help text"
- 5085fc4 (2025-12-29): "Add comprehensive help text and usage examples"

**Test commands affected**:
- `claudeutils collect --help`
- `claudeutils analyze --help`
- `claudeutils rules --help`
- `claudeutils tokens --help`

Note: The composition API work (Cycle 4.1-4.3) correctly did NOT add help text tests for `compose` command.
